{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1vQFFt0UaVQ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUyrVYZT72bk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLUo34S3CXhK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "dMW69m0Cafjv",
    "outputId": "c4585e4b-d38b-4c83-c121-39e8ad4a08ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Hx8yFdI1UBnG",
    "outputId": "9edd6210-666f-438f-cbc0-01766b0c77d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/content/gdrive/My Drive/ML colab datasets/crowdflower-search-relevance/kappa_intuition.py' -> './kappa_intuition.py'\n",
      "'/content/gdrive/My Drive/ML colab datasets/crowdflower-search-relevance/kaggle.json' -> '/root/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# data_dir = '/content/gdrive/My Drive/ML colab datasets/crowdflower-search-relevance'\n",
    "\n",
    "# !ls '{data_dir}'\n",
    "\n",
    "# !cp -v '{data_dir}/kappa_intuition.py' ./\n",
    "# !mkdir -p /root/.kaggle\n",
    "# !cp -v '{data_dir}/kaggle.json' /root/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jj1mkYYASd6V"
   },
   "outputs": [],
   "source": [
    "from kappa_intuition import quadratic_weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "8Dxyb9ua8fUp",
    "outputId": "b3bd9e92-83e8-4b94-e8b1-8f60efad6b41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bridal shower decorations</td>\n",
       "      <td>Accent Pillow with Heart Design - Red/Black</td>\n",
       "      <td>Red satin accent pillow embroidered with a hea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>led christmas lights</td>\n",
       "      <td>Set of 10 Battery Operated Multi LED Train Chr...</td>\n",
       "      <td>Set of 10 Battery Operated Train Christmas Lig...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>projector</td>\n",
       "      <td>ViewSonic Pro8200 DLP Multimedia Projector</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>wine rack</td>\n",
       "      <td>Concept Housewares WR-44526 Solid-Wood Ceiling...</td>\n",
       "      <td>Like a silent and sturdy tree, the Southern En...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>light bulb</td>\n",
       "      <td>Wintergreen Lighting Christmas LED Light Bulb ...</td>\n",
       "      <td>WTGR1011\\nFeatures\\nNickel base, 60,000 averag...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      query  ... median_relevance relevance_variance\n",
       "0   1  bridal shower decorations  ...                1              0.000\n",
       "1   2       led christmas lights  ...                4              0.000\n",
       "2   4                  projector  ...                4              0.471\n",
       "3   5                  wine rack  ...                4              0.000\n",
       "4   7                 light bulb  ...                2              0.471\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = f'{data_dir}/train.csv'\n",
    "df = pd.read_csv(train_file)\n",
    "df.fillna('', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eOPJ4zISGyit",
    "outputId": "6822f710-b252-489c-d426-3015e46d1892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('book')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dL0MFMHrBSkC"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "ignore_set = set(stopwords.words('english') + list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTIpohom-lKf"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.replace('\\\\n', '')\n",
    "    text = text.replace('\\\\t', ' ')\n",
    "    text = text.lower().strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = list(filter(lambda x: x not in ignore_set, tokens))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mj3dROFzUTjt"
   },
   "outputs": [],
   "source": [
    "def get_num_words(text):\n",
    "    return len(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNI8TZjfUSzd"
   },
   "outputs": [],
   "source": [
    "def get_lengths(df):\n",
    "    return list(map(get_num_words, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2ej6lkrUSjH"
   },
   "outputs": [],
   "source": [
    "title_lens = get_lengths(df['product_title'])\n",
    "np.median(title_lens), np.mean(title_lens), np.min(title_lens), np.max(title_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QL1BUtSbUSAg",
    "outputId": "2bb93176-b408-47a2-840c-a94878089b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 2.361783815711754, 1, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_lens = get_lengths(df['query'])\n",
    "np.median(query_lens), np.mean(query_lens), np.min(query_lens), np.max(query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEBEuOUBUROG"
   },
   "outputs": [],
   "source": [
    "desc_lens = get_lengths(df['product_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lmY6Z53yUbJd",
    "outputId": "49d5f12d-5bd1-4bec-ef75-42f72c4ad269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.0, 43.05237251427447, 0, 1853)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.hist(desc_lens)\n",
    "np.median(desc_lens), np.mean(desc_lens), np.min(desc_lens), np.max(desc_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DJm_vqs7dJz"
   },
   "outputs": [],
   "source": [
    "outs = list(df['median_relevance'])\n",
    "# plt.hist(outs)\n",
    "from collections import Counter\n",
    "label_counter = Counter(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBMoYRjLYKh"
   },
   "outputs": [],
   "source": [
    "def loadGloveModel(glove_file):\n",
    "    print(\"Loading Glove Model\")\n",
    "    model = {}\n",
    "    with open(glove_file,'r') as f:\n",
    "        for line in f:\n",
    "            splitLine = line.split()\n",
    "            word = splitLine[0]\n",
    "            embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "            model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "uFgMWMOhA35v",
    "outputId": "ab9c21b3-3f20-4919-e6a2-a20cbd247f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove_file = f'{data_dir}/glove.6B.100d.txt'\n",
    "try:\n",
    "    glove_model.keys()\n",
    "except:\n",
    "    glove_model = loadGloveModel(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRc2YtLv7HVh"
   },
   "outputs": [],
   "source": [
    "def super_sample(df):\n",
    "    import random\n",
    "    all_words =list(glove_model.keys())\n",
    "    def replace_tokens(text, prob):\n",
    "        tokens = word_tokenize(text)\n",
    "        num = int(len(tokens) * prob + 0.25)\n",
    "        indices = random.sample(range(len(tokens)), num)\n",
    "        for i in indices:\n",
    "            tokens[i] = random.choice(all_words)\n",
    "        # print(len(tokens), num)\n",
    "        # print(text)\n",
    "        text = ' '.join(tokens)\n",
    "        # print(text)\n",
    "        return text\n",
    "\n",
    "    max_ = max(label_counter.values())\n",
    "    \n",
    "    new_data = []\n",
    "    for k, v in label_counter.items():\n",
    "        if k == 1:\n",
    "            prob = 0.5\n",
    "        else:\n",
    "            continue\n",
    "        num = min(max_ - v, v) \n",
    "        if num < 1:\n",
    "            continue\n",
    "        else:\n",
    "            times = num // v + 1\n",
    "            arr = []\n",
    "            for i in range(times):\n",
    "                arr.append(df[df.median_relevance == k].values)\n",
    "            arr = np.concatenate(arr, axis=0)\n",
    "            # query\n",
    "            for i in range(len(arr)):\n",
    "                text = arr[i, 1]\n",
    "                arr[i, 1] = replace_tokens(text, prob)\n",
    "            # title\n",
    "            for i in range(len(arr)):\n",
    "                text = arr[i, 2]\n",
    "                arr[i, 2] = replace_tokens(text, prob)\n",
    "            new_data.append(arr)\n",
    "    new_data = np.concatenate(new_data, axis = 0)\n",
    "    print(new_data.shape)\n",
    "    new_df = pd.DataFrame(data=new_data, columns=df.columns)       \n",
    "    return df.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSo2esTGUFvq"
   },
   "outputs": [],
   "source": [
    "def text_to_tensor(text, max_len):\n",
    "    tokens = preprocess(text)\n",
    "    tokens = tokens[:max_len]\n",
    "    tensor = []\n",
    "    dim = glove_model['the'].shape[0]\n",
    "    for token in tokens:\n",
    "        if token in glove_model:\n",
    "            tensor.append(glove_model[token])\n",
    "        else:\n",
    "            tensor.append(np.random.uniform(-0.05, 0.05, size=(dim,)))\n",
    "    for i in range(max_len - len(tokens)):\n",
    "        tensor.append(np.zeros((dim,)))\n",
    "    return np.array(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cPxfa5YV7lp"
   },
   "outputs": [],
   "source": [
    "def batch_text_to_tensor(texts, max_len):\n",
    "    batch_tensor = []\n",
    "    for html in texts:\n",
    "        # soup = BeautifulSoup(html)\n",
    "        # text = soup.get_text()\n",
    "        text = html\n",
    "        t = text_to_tensor(text, max_len)\n",
    "        batch_tensor.append(t)\n",
    "    return np.array(batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dckibAgCIxoU"
   },
   "outputs": [],
   "source": [
    "dim = 100\n",
    "query_max_len = 8\n",
    "title_max_len = 20\n",
    "desc_max_len = 40\n",
    "output_dim = 4\n",
    "dropout_prob = 0.\n",
    "model_file = f'{data_dir}/model_1.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlKzGyGuVB6h"
   },
   "outputs": [],
   "source": [
    "def get_vectorized_data(df):\n",
    "    ids = list(df['id'])\n",
    "    queries = list(df['query'])\n",
    "    titles = list(df['product_title'])\n",
    "    descs = list(df['product_description'])\n",
    "    outputs = list(df['median_relevance'])\n",
    "    Xq = batch_text_to_tensor(queries, query_max_len)\n",
    "    # Xq = np.mean(Xq, axis=1)\n",
    "    print(Xq.shape)\n",
    "    Xt = batch_text_to_tensor(titles, title_max_len)\n",
    "    # Xt = np.mean(Xt, axis=1)\n",
    "    print(Xt.shape)\n",
    "    # Xd = batch_text_to_tensor(descs, desc_max_len)\n",
    "    # print(Xd.shape)\n",
    "    # Xd = list(range(len(descs)))\n",
    "    Y = np.array(list(map(lambda x: x - 1, outputs)))\n",
    "    print(Y.shape)\n",
    "    return Xq, Xt, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZFGfhrc1FYM"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "eYsw0k6l3VBN",
    "outputId": "9bdd2ef4-7e85-465f-b7a3-cc6088fbc521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8634\n",
      "(1308, 6)\n",
      "9942\n",
      "Counter({4: 5283, 1: 1962, 3: 1455, 2: 1242})\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "super_df = super_sample(train_df)\n",
    "print(len(super_df))\n",
    "print(Counter(super_df['median_relevance']))\n",
    "train_df = shuffle(super_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "4a1aAi_VXAaQ",
    "outputId": "e14508ca-b34f-424d-fc34-b16cbe298415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9942, 8, 100)\n",
      "(9942, 20, 100)\n",
      "(9942,)\n"
     ]
    }
   ],
   "source": [
    "Xq, Xt, Y = get_vectorized_data(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "vBYH_ifRHrNz",
    "outputId": "38291a70-4fd2-48fb-f50a-86985a50a75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1524, 8, 100)\n",
      "(1524, 20, 100)\n",
      "(1524,)\n"
     ]
    }
   ],
   "source": [
    "Xq_v, Xt_v, Y_v = get_vectorized_data(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Kb9mHtaV3-6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8RiKZ2eDyvx"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, LSTM, Bidirectional, Concatenate, CuDNNLSTM, Embedding, Dropout, Dot\n",
    "from keras import regularizers\n",
    "from keras.backend import batch_dot\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9l5CSWfsH-Pk"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "query_in = Input(shape=(query_max_len, dim), name='query_in')\n",
    "title_in = Input(shape=(title_max_len, dim), name='title_in')\n",
    "\n",
    "r1, r2, r3, r4 = None, None, None, None\n",
    "# r1=regularizers.l2(0.001)\n",
    "# r2=regularizers.l2(0.001)\n",
    "r3=regularizers.l2(0.001)\n",
    "r4=regularizers.l2(0.001)\n",
    "\n",
    "q_hidden = CuDNNLSTM(units=100, kernel_regularizer=r3)(query_in)\n",
    "t_hidden = Bidirectional(CuDNNLSTM(units=100, kernel_regularizer=r4), merge_mode='concat')(title_in)\n",
    "arr = []\n",
    "for i in range(8):\n",
    "    dense1 = Dense(100, activation='tanh', name=f'dense_{i}_1')\n",
    "    dropout = Dropout(dropout_prob, name=f'dropout_{i}')\n",
    "    dense2 = Dense(100, activation='tanh', name=f'dense_{i}_2')\n",
    "    q_scaled = dropout(dense1(q_hidden))\n",
    "    t_scaled = dropout(dense2(t_hidden))\n",
    "    dot_prod = Dot(axes=-1, name=f'dot_{i}')([q_scaled, t_scaled])\n",
    "    arr.append(dot_prod)\n",
    "\n",
    "joint = Concatenate(axis=1)(arr)\n",
    "joint = Dense(8, activation='relu')(joint)\n",
    "joint = Dense(4, activation='relu')(joint)\n",
    "score = Dense(1, activation='relu')(joint)\n",
    "\n",
    "model = Model(inputs=[query_in, title_in], outputs=score)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niyCPLYaw2XE"
   },
   "outputs": [],
   "source": [
    "optim = Adam(lr=1e-4, clipnorm=5., clipvalue=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1i-MeiyNZn7"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mae', metrics=['mae'], optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1WscXk3s9c1"
   },
   "outputs": [],
   "source": [
    "# ckpt_clbk = ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_clbk = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=7, verbose=2, mode='auto', baseline=None, restore_best_weights=True)\n",
    "callbacks = [early_clbk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3COJNTCSV4g0",
    "outputId": "d92fcb02-bfc3-4f86-db1a-afef73342da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8450 samples, validate on 1492 samples\n",
      "Epoch 1/50\n",
      "8450/8450 [==============================] - 10s 1ms/step - loss: 1.4988 - mean_absolute_error: 1.1017 - val_loss: 1.1534 - val_mean_absolute_error: 0.8121\n",
      "Epoch 2/50\n",
      "8450/8450 [==============================] - 6s 701us/step - loss: 1.0461 - mean_absolute_error: 0.7400 - val_loss: 0.9553 - val_mean_absolute_error: 0.6784\n",
      "Epoch 3/50\n",
      "8450/8450 [==============================] - 6s 699us/step - loss: 0.9105 - mean_absolute_error: 0.6546 - val_loss: 0.8853 - val_mean_absolute_error: 0.6483\n",
      "Epoch 4/50\n",
      "8450/8450 [==============================] - 6s 694us/step - loss: 0.8378 - mean_absolute_error: 0.6159 - val_loss: 0.8499 - val_mean_absolute_error: 0.6418\n",
      "Epoch 5/50\n",
      "8450/8450 [==============================] - 6s 696us/step - loss: 0.7926 - mean_absolute_error: 0.5955 - val_loss: 0.8056 - val_mean_absolute_error: 0.6187\n",
      "Epoch 6/50\n",
      "8450/8450 [==============================] - 6s 699us/step - loss: 0.7581 - mean_absolute_error: 0.5796 - val_loss: 0.7756 - val_mean_absolute_error: 0.6050\n",
      "Epoch 7/50\n",
      "8450/8450 [==============================] - 6s 712us/step - loss: 0.7276 - mean_absolute_error: 0.5635 - val_loss: 0.7537 - val_mean_absolute_error: 0.5960\n",
      "Epoch 8/50\n",
      "8450/8450 [==============================] - 6s 698us/step - loss: 0.7057 - mean_absolute_error: 0.5533 - val_loss: 0.7586 - val_mean_absolute_error: 0.6112\n",
      "Epoch 9/50\n",
      "8450/8450 [==============================] - 6s 694us/step - loss: 0.6852 - mean_absolute_error: 0.5422 - val_loss: 0.7221 - val_mean_absolute_error: 0.5832\n",
      "Epoch 10/50\n",
      "8450/8450 [==============================] - 6s 712us/step - loss: 0.6709 - mean_absolute_error: 0.5355 - val_loss: 0.7238 - val_mean_absolute_error: 0.5918\n",
      "Epoch 11/50\n",
      "8450/8450 [==============================] - 6s 710us/step - loss: 0.6575 - mean_absolute_error: 0.5285 - val_loss: 0.7057 - val_mean_absolute_error: 0.5796\n",
      "Epoch 12/50\n",
      "8450/8450 [==============================] - 6s 697us/step - loss: 0.6460 - mean_absolute_error: 0.5225 - val_loss: 0.6960 - val_mean_absolute_error: 0.5749\n",
      "Epoch 13/50\n",
      "8450/8450 [==============================] - 6s 694us/step - loss: 0.6368 - mean_absolute_error: 0.5178 - val_loss: 0.6834 - val_mean_absolute_error: 0.5666\n",
      "Epoch 14/50\n",
      "8450/8450 [==============================] - 6s 692us/step - loss: 0.6293 - mean_absolute_error: 0.5142 - val_loss: 0.7032 - val_mean_absolute_error: 0.5900\n",
      "Epoch 15/50\n",
      "8450/8450 [==============================] - 6s 694us/step - loss: 0.6228 - mean_absolute_error: 0.5112 - val_loss: 0.6772 - val_mean_absolute_error: 0.5672\n",
      "Epoch 16/50\n",
      "8450/8450 [==============================] - 6s 694us/step - loss: 0.6125 - mean_absolute_error: 0.5040 - val_loss: 0.6635 - val_mean_absolute_error: 0.5565\n",
      "Epoch 17/50\n",
      "8450/8450 [==============================] - 6s 691us/step - loss: 0.6018 - mean_absolute_error: 0.4961 - val_loss: 0.6576 - val_mean_absolute_error: 0.5534\n",
      "Epoch 18/50\n",
      "8450/8450 [==============================] - 6s 694us/step - loss: 0.6004 - mean_absolute_error: 0.4973 - val_loss: 0.6577 - val_mean_absolute_error: 0.5556\n",
      "Epoch 19/50\n",
      "8450/8450 [==============================] - 6s 700us/step - loss: 0.5896 - mean_absolute_error: 0.4886 - val_loss: 0.6530 - val_mean_absolute_error: 0.5531\n",
      "Epoch 20/50\n",
      "8450/8450 [==============================] - 6s 706us/step - loss: 0.5865 - mean_absolute_error: 0.4876 - val_loss: 0.6563 - val_mean_absolute_error: 0.5583\n",
      "Epoch 21/50\n",
      "8450/8450 [==============================] - 6s 726us/step - loss: 0.5798 - mean_absolute_error: 0.4828 - val_loss: 0.6552 - val_mean_absolute_error: 0.5591\n",
      "Epoch 22/50\n",
      "8450/8450 [==============================] - 6s 724us/step - loss: 0.5781 - mean_absolute_error: 0.4828 - val_loss: 0.6465 - val_mean_absolute_error: 0.5521\n",
      "Epoch 23/50\n",
      "8450/8450 [==============================] - 6s 697us/step - loss: 0.5686 - mean_absolute_error: 0.4750 - val_loss: 0.6387 - val_mean_absolute_error: 0.5459\n",
      "Epoch 24/50\n",
      "8450/8450 [==============================] - 6s 687us/step - loss: 0.5644 - mean_absolute_error: 0.4723 - val_loss: 0.6414 - val_mean_absolute_error: 0.5500\n",
      "Epoch 25/50\n",
      "8450/8450 [==============================] - 6s 692us/step - loss: 0.5626 - mean_absolute_error: 0.4719 - val_loss: 0.6293 - val_mean_absolute_error: 0.5391\n",
      "Epoch 26/50\n",
      "8450/8450 [==============================] - 6s 685us/step - loss: 0.5550 - mean_absolute_error: 0.4655 - val_loss: 0.6354 - val_mean_absolute_error: 0.5464\n",
      "Epoch 27/50\n",
      "8450/8450 [==============================] - 6s 693us/step - loss: 0.5551 - mean_absolute_error: 0.4667 - val_loss: 0.6260 - val_mean_absolute_error: 0.5382\n",
      "Epoch 28/50\n",
      "8450/8450 [==============================] - 6s 687us/step - loss: 0.5461 - mean_absolute_error: 0.4588 - val_loss: 0.6111 - val_mean_absolute_error: 0.5244\n",
      "Epoch 29/50\n",
      "8450/8450 [==============================] - 6s 690us/step - loss: 0.5393 - mean_absolute_error: 0.4532 - val_loss: 0.6311 - val_mean_absolute_error: 0.5456\n",
      "Epoch 30/50\n",
      "8450/8450 [==============================] - 6s 692us/step - loss: 0.5333 - mean_absolute_error: 0.4483 - val_loss: 0.6248 - val_mean_absolute_error: 0.5403\n",
      "Epoch 31/50\n",
      "8450/8450 [==============================] - 6s 710us/step - loss: 0.5294 - mean_absolute_error: 0.4455 - val_loss: 0.6052 - val_mean_absolute_error: 0.5217\n",
      "Epoch 32/50\n",
      "8450/8450 [==============================] - 6s 704us/step - loss: 0.5283 - mean_absolute_error: 0.4453 - val_loss: 0.6095 - val_mean_absolute_error: 0.5269\n",
      "Epoch 33/50\n",
      "8450/8450 [==============================] - 6s 688us/step - loss: 0.5236 - mean_absolute_error: 0.4414 - val_loss: 0.6029 - val_mean_absolute_error: 0.5212\n",
      "Epoch 34/50\n",
      "8450/8450 [==============================] - 6s 697us/step - loss: 0.5173 - mean_absolute_error: 0.4360 - val_loss: 0.6002 - val_mean_absolute_error: 0.5193\n",
      "Epoch 35/50\n",
      "8450/8450 [==============================] - 6s 693us/step - loss: 0.5116 - mean_absolute_error: 0.4312 - val_loss: 0.6153 - val_mean_absolute_error: 0.5352\n",
      "Epoch 36/50\n",
      "8450/8450 [==============================] - 6s 685us/step - loss: 0.5111 - mean_absolute_error: 0.4313 - val_loss: 0.6068 - val_mean_absolute_error: 0.5275\n",
      "Epoch 37/50\n",
      "8450/8450 [==============================] - 6s 688us/step - loss: 0.5106 - mean_absolute_error: 0.4315 - val_loss: 0.5961 - val_mean_absolute_error: 0.5174\n",
      "Epoch 38/50\n",
      "8450/8450 [==============================] - 6s 688us/step - loss: 0.5054 - mean_absolute_error: 0.4270 - val_loss: 0.6142 - val_mean_absolute_error: 0.5362\n",
      "Epoch 39/50\n",
      "8450/8450 [==============================] - 6s 686us/step - loss: 0.4971 - mean_absolute_error: 0.4193 - val_loss: 0.6052 - val_mean_absolute_error: 0.5278\n",
      "Epoch 40/50\n",
      "8450/8450 [==============================] - 6s 691us/step - loss: 0.4956 - mean_absolute_error: 0.4185 - val_loss: 0.5888 - val_mean_absolute_error: 0.5121\n",
      "Epoch 41/50\n",
      "8450/8450 [==============================] - 6s 697us/step - loss: 0.4928 - mean_absolute_error: 0.4163 - val_loss: 0.5942 - val_mean_absolute_error: 0.5181\n",
      "Epoch 42/50\n",
      "8450/8450 [==============================] - 6s 706us/step - loss: 0.4835 - mean_absolute_error: 0.4076 - val_loss: 0.6156 - val_mean_absolute_error: 0.5400\n",
      "Epoch 43/50\n",
      "8450/8450 [==============================] - 6s 689us/step - loss: 0.4847 - mean_absolute_error: 0.4094 - val_loss: 0.6059 - val_mean_absolute_error: 0.5309\n",
      "Epoch 44/50\n",
      "8450/8450 [==============================] - 6s 689us/step - loss: 0.4811 - mean_absolute_error: 0.4062 - val_loss: 0.5872 - val_mean_absolute_error: 0.5126\n",
      "Epoch 45/50\n",
      "8450/8450 [==============================] - 6s 682us/step - loss: 0.4709 - mean_absolute_error: 0.3966 - val_loss: 0.5871 - val_mean_absolute_error: 0.5130\n",
      "Epoch 46/50\n",
      "8450/8450 [==============================] - 6s 685us/step - loss: 0.4679 - mean_absolute_error: 0.3940 - val_loss: 0.5876 - val_mean_absolute_error: 0.5140\n",
      "Epoch 47/50\n",
      "8450/8450 [==============================] - 6s 693us/step - loss: 0.4661 - mean_absolute_error: 0.3928 - val_loss: 0.5951 - val_mean_absolute_error: 0.5221\n",
      "Epoch 48/50\n",
      "8450/8450 [==============================] - 6s 690us/step - loss: 0.4634 - mean_absolute_error: 0.3905 - val_loss: 0.5952 - val_mean_absolute_error: 0.5225\n",
      "Epoch 49/50\n",
      "8450/8450 [==============================] - 6s 692us/step - loss: 0.4618 - mean_absolute_error: 0.3893 - val_loss: 0.6022 - val_mean_absolute_error: 0.5298\n",
      "Epoch 50/50\n",
      "8450/8450 [==============================] - 6s 689us/step - loss: 0.4560 - mean_absolute_error: 0.3839 - val_loss: 0.5859 - val_mean_absolute_error: 0.5141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2643157198>"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[Xq, Xt], y=Y, batch_size=32, epochs=50, validation_split=0.15, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1KyyI6ce1eQe"
   },
   "outputs": [],
   "source": [
    "def convert_output(y_pred):\n",
    "    if y_pred <= 0.5:\n",
    "        y_pred = 0\n",
    "    elif y_pred <= 1.5:\n",
    "        y_pred = 1\n",
    "    elif y_pred <= 2.5:\n",
    "        y_pred = 2\n",
    "    else:\n",
    "        y_pred = 3\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6_sqllz2Wol5",
    "outputId": "b069f7a8-2d8e-4ad5-b664-b26f91b8767e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8040029033652715"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.predict(x=[Xq, Xt], batch_size=32)\n",
    "y_preds = list(map(convert_output, outputs))\n",
    "quadratic_weighted_kappa(Y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2CF5oBWP1tzr",
    "outputId": "1406da8a-b86a-4951-cc91-7fe1bb393215"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5278523120432563"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.predict(x=[Xq_v, Xt_v], batch_size=32)\n",
    "y_preds = list(map(convert_output, outputs))\n",
    "quadratic_weighted_kappa(Y_v, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "Tcxz9BccDyEP",
    "outputId": "6ccc6a26-bcef-47a1-b739-4da48cdea7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.38      0.42       120\n",
      "           1       0.50      0.23      0.31       234\n",
      "           2       0.31      0.29      0.30       282\n",
      "           3       0.74      0.88      0.80       888\n",
      "\n",
      "    accuracy                           0.63      1524\n",
      "   macro avg       0.51      0.44      0.46      1524\n",
      "weighted avg       0.60      0.63      0.60      1524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_v, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "D7MMAQWkEDLA",
    "outputId": "a2fd898e-ee25-45f1-f63f-230f20affc27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 45  21  27  27]\n",
      " [ 21  53  74  86]\n",
      " [ 17  19  83 163]\n",
      " [  9  14  85 780]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_v, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grSP1WqBAUhg"
   },
   "outputs": [],
   "source": [
    "test_file = f'{data_dir}/test.csv'\n",
    "test_df = pd.read_csv(test_file)\n",
    "test_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyneQagZ4zHC"
   },
   "outputs": [],
   "source": [
    "def get_vectorized_test_data(df):\n",
    "    ids = list(df['id'])\n",
    "    queries = list(df['query'])\n",
    "    titles = list(df['product_title'])\n",
    "    descs = list(df['product_description'])\n",
    "    Xq = batch_text_to_tensor(queries, query_max_len)\n",
    "    print(Xq.shape)\n",
    "    Xt = batch_text_to_tensor(titles, title_max_len)\n",
    "    print(Xt.shape)\n",
    "    return Xq, Xt, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sMAL_0s145Ot",
    "outputId": "7c8481de-5012-42d4-b87d-2ba052a9f868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22513, 8, 100)\n",
      "(22513, 20, 100)\n"
     ]
    }
   ],
   "source": [
    "Xq, Xt, ids = get_vectorized_test_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "11wKbqEX47cP",
    "outputId": "7a653105-4476-4a8f-eab4-56505471fc0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22513, 22513)"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.predict(x=[Xq, Xt], batch_size=32)\n",
    "y_preds = list(map(convert_output, outputs))\n",
    "len(ids), len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBp9Kx6c4_uC"
   },
   "outputs": [],
   "source": [
    "y_preds = list(map(lambda x: x + 1, y_preds))\n",
    "submission = pd.DataFrame({\"id\": ids, \"prediction\": y_preds})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Tr4A1P4BX7AJ",
    "outputId": "a4b3d8f9-6530-4a4c-f9b9-1122eb27db4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "100% 168k/168k [00:02<00:00, 79.5kB/s]\n",
      "Successfully submitted to Crowdflower Search Results Relevance"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c crowdflower-search-relevance -f submission.csv -m \"DL multi head dotproduct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sslVKxJPQ0bF"
   },
   "outputs": [],
   "source": [
    "model.save(model_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word_lstm_org.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
